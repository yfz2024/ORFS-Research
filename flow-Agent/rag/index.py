import os
import pickle
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from .util import load_multiple_qa_files, prepareDocuments

# æ•°æ®ä¸æ¨¡å‹è·¯å¾„
BASE_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.join(BASE_DIR, "..", "rag_date")
EMB_PATH = os.path.join(DATA_DIR, "embeddings.npy")
DOCS_PATH = os.path.join(DATA_DIR, "docs.pkl")

# é»˜è®¤æ¨¡å‹è·¯å¾„ï¼ˆå¯ä¿®æ”¹ï¼‰
DEFAULT_MODEL_PATH = "/mnt/c/Users/Public/OpenROAD-flow-scripts/orfs-agent/models/mxbai-embed-large-v1"

# ============================================================
# ğŸ”¹ æ„å»ºå¹¶ä¿å­˜ Embedding å‘é‡åº“
# ============================================================
def build_and_save_embeddings(base_dir="/mnt/e/OpenROAD-flow-scripts/orfs-agent/EDA-Corpus-main/Augmented_Data/Question-Answer",
                              model_name=DEFAULT_MODEL_PATH):
    """
    ä» Flow / General / Tools ä¸‰ä¸ª CSV æ„å»ºå‘é‡åº“å¹¶ä¿å­˜ã€‚
    """
    print("[RAG] æ­£åœ¨åŠ è½½ QA æ–‡ä»¶...")
    df = load_multiple_qa_files(base_dir)

    # å‡†å¤‡æ–‡æ¡£
    docs, docsDict = prepareDocuments(df)

    # æ„å»ºæ¨¡å‹
    print(f"[RAG] æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹ï¼š{model_name}")
    model = SentenceTransformer(model_name)

    # ç”Ÿæˆå‘é‡
    print("[RAG] æ­£åœ¨ç”Ÿæˆæ–‡æœ¬å‘é‡...")
    embeddings = model.encode(docs, convert_to_numpy=True, show_progress_bar=True)

    # ç¡®ä¿ä¿å­˜è·¯å¾„å­˜åœ¨
    os.makedirs(DATA_DIR, exist_ok=True)

    # ä¿å­˜
    np.save(EMB_PATH, embeddings)
    with open(DOCS_PATH, "wb") as f:
        pickle.dump((docs, docsDict), f)

    print(f"[RAG] âœ… å‘é‡åº“æ„å»ºå®Œæˆå¹¶ä¿å­˜åˆ° {DATA_DIR}")


# ============================================================
# ğŸ”¹ åŠ è½½å·²ä¿å­˜çš„å‘é‡åº“
# ============================================================
def load_embeddings_and_docs():
    if not os.path.exists(EMB_PATH) or not os.path.exists(DOCS_PATH):
        raise FileNotFoundError("[RAG] å‘é‡åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ build_and_save_embeddings()")

    embeddings = np.load(EMB_PATH)
    with open(DOCS_PATH, "rb") as f:
        docs, docsDict = pickle.load(f)

    print(f"[RAG] æˆåŠŸåŠ è½½å‘é‡åº“ï¼Œå…± {len(docs)} æ¡æ–‡æ¡£ã€‚")
    return embeddings, docs, docsDict